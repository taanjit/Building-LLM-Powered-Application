{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:3b\",temperature=0)\n",
    "model=llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Provide clear instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant that helps human by generating tutorials given a text.\n",
    "You will be provided with a text. If the text contains any kind of istructions on how to proceed with something, \n",
    "generate a tutorial in a bullet list.\n",
    "Otherwise, inform the user that the text does not contain any instructions.\n",
    "\n",
    "Text: \n",
    "\"\"\"\n",
    "\n",
    "instructions = \"\"\"\n",
    "To prepare the known sauce from Genova, Italy, you can start by toasting the pine nuts to then coarsely \n",
    "chop them in a kitchen mortar together with basil and garlic. Then, add half of the oil in the kitchen mortar\n",
    " and season with salt and pepper.\n",
    "Finally, transfer the pesto to a bowl and stir in the grated Parmesan cheese.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a tutorial based on the provided text:\n",
      "\n",
      "**Preparing Genovese Pesto Sauce**\n",
      "\n",
      "* **Step 1: Toast Pine Nuts**\n",
      "\t+ Preheat your oven or dry skillet over medium heat.\n",
      "\t+ Add pine nuts to the preheated oven or skillet and toast until fragrant, about 2-3 minutes.\n",
      "* **Step 2: Chop Pine Nuts with Basil and Garlic**\n",
      "\t+ Transfer toasted pine nuts to a kitchen mortar.\n",
      "\t+ Add chopped basil and garlic to the mortar.\n",
      "\t+ Coarsely chop the ingredients together using the pestle or back of a spoon until well combined.\n",
      "* **Step 3: Mix Pesto Sauce**\n",
      "\t+ Add half of the oil to the mortar with the chopped mixture.\n",
      "\t+ Season with salt and pepper to taste.\n",
      "\t+ Use the pestle or spoon to mix the sauce until smooth.\n",
      "* **Step 4: Finish Pesto Sauce**\n",
      "\t+ Transfer the pesto sauce to a bowl.\n",
      "\t+ Stir in grated Parmesan cheese until well combined.\n",
      "\n",
      "Enjoy your homemade Genovese pesto sauce!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prepare the messages in the required format\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=instructions),\n",
    "]\n",
    "\n",
    "# Invoke the LLM\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text does not contain any instructions or guidance on how to proceed with something. It appears to be a descriptive passage about a scene, but it does not provide any specific actions or steps for the reader to follow.\n",
      "\n",
      "If you would like, I can help generate a tutorial based on a different text that contains instructions. Please provide another text, and I'll be happy to assist!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prepare the messages in the required format\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content='the sun is shining and dogs are running on the beach.'),\n",
    "]\n",
    "\n",
    "# Invoke the LLM\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split complext tasks into subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant that summarize articles. \n",
    "To complete this task, do the following subtasks:\n",
    "\n",
    "Read the provided article context comprehensively and identified the main topic and key points\n",
    "Generated a paragraph summary of the current article context that captures the essential information and conveys the main idea\n",
    "Print each step of the proces.\n",
    "Article:\n",
    "\"\"\"\n",
    "\n",
    "article = \"\"\"\n",
    "Recurrent neural networks, long short-term memory and gated recurrent neural networks\n",
    "in particular, have been firmly established as state of the art approaches in sequence modeling and\n",
    "transduction problems such as language modeling and machine translation. Numerous\n",
    "efforts have since continued to push the boundaries of recurrent language models and encoder-decoder\n",
    "architectures.\n",
    "Recurrent models typically factor computation along the symbol positions of the input and output\n",
    "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
    "states ht, as a function of the previous hidden state ht-1 and the input for position t. This inherently\n",
    "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
    "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
    "significant improvements in computational efficiency through factorization tricks and conditional\n",
    "computation, while also improving model performance in case of the latter. The fundamental\n",
    "constraint of sequential computation, however, remains.\n",
    "Attention mechanisms have become an integral part of compelling sequence modeling and transduction \n",
    "models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
    "the input or output sequences. In all but a few cases, however, such attention mechanisms\n",
    "are used in conjunction with a recurrent network.\n",
    "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
    "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
    "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
    "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the steps I took to summarize the article:\n",
      "\n",
      "**Step 1: Reading and Comprehension**\n",
      "\n",
      "I read the provided article context comprehensively, identifying the main topic and key points. The article discusses recurrent neural networks (RNNs), long short-term memory (LSTM) networks, gated recurrent neural networks (GRNs), and attention mechanisms in sequence modeling and transduction problems.\n",
      "\n",
      "**Step 2: Identifying Main Topic**\n",
      "\n",
      "The main topic of the article is the development of a new model architecture called the Transformer, which replaces traditional RNN-based approaches with an attention mechanism to draw global dependencies between input and output sequences.\n",
      "\n",
      "**Step 3: Generating Summary Paragraph**\n",
      "\n",
      "Here is a paragraph summary of the current article context that captures the essential information and conveys the main idea:\n",
      "\n",
      "\"Recurrent neural networks have been a cornerstone of sequence modeling and transduction problems, but recent work has focused on improving their efficiency and performance. The Transformer model architecture proposes an alternative approach by relying entirely on attention mechanisms to draw global dependencies between input and output sequences. This allows for significant parallelization and enables the model to achieve state-of-the-art translation quality in a remarkably short training time of just twelve hours on eight GPUs.\"\n",
      "\n",
      "**Step 4: Printing Summary**\n",
      "\n",
      "Here is the summary paragraph:\n",
      "\n",
      "Recurrent neural networks have been a cornerstone of sequence modeling and transduction problems, but recent work has focused on improving their efficiency and performance. The Transformer model architecture proposes an alternative approach by relying entirely on attention mechanisms to draw global dependencies between input and output sequences. This allows for significant parallelization and enables the model to achieve state-of-the-art translation quality in a remarkably short training time of just twelve hours on eight GPUs.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prepare the messages in the required format\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=article),\n",
    "]\n",
    "\n",
    "# Invoke the LLM\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Ask for justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in generating essays shorter than 500 words.\n",
    "Given a statement, develop the essay the best you can.\n",
    "Once the essay is generated, provide clear justifications and explanations of the reasons behind the sentences you generated.\n",
    "\n",
    "Statement:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "statement = \"\"\"\n",
    "An introduction to mammals like chickens.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an essay on introducing mammals like chickens:\n",
      "\n",
      "Mammals are often misunderstood as being exclusively large, furry creatures. However, this couldn't be further from the truth. In fact, there are many fascinating examples of mammals that defy conventional expectations. One such example is the humble chicken (Gallus gallus domesticus). Yes, you read that right - chickens are indeed mammals.\n",
      "\n",
      "From a biological perspective, chickens are warm-blooded, meaning they regulate their own body temperature, rather than relying on external sources like sunlight or fire to stay cozy. They also produce milk to feed their young, a characteristic unique to mammals. In fact, chicken mothers will often go to great lengths to care for their chicks, including brooding them under their wings and providing them with nourishing food.\n",
      "\n",
      "Despite these mammalian traits, chickens are often lumped in with birds due to their physical characteristics and behaviors. However, this classification is based on outdated taxonomic thinking. In reality, chickens belong to the class Aves, but more specifically, they are part of the order Galliformes, which also includes turkeys, pheasants, and quails.\n",
      "\n",
      "So why do we often think of chickens as birds? One reason is that their skeletal system is designed for flight, with hollow bones and three-toed feet. However, this doesn't mean they're incapable of movement or agility on land. In fact, chickens are surprisingly adept at navigating complex environments and can even climb trees.\n",
      "\n",
      "In conclusion, the idea that mammals are exclusively large, furry creatures is a misconception. Chickens, in particular, embody many mammalian characteristics, from their warm-blooded nature to their nurturing behavior. By recognizing these traits, we can gain a deeper appreciation for the diversity of life on Earth and challenge our preconceived notions about what it means to be a mammal.\n",
      "\n",
      "Justifications:\n",
      "\n",
      "* I started by introducing the idea that mammals are often misunderstood, setting the stage for the rest of the essay.\n",
      "* The sentence \"One such example is the humble chicken (Gallus gallus domesticus)\" was chosen because it's a relatable and unexpected subject, making the reader more likely to engage with the essay.\n",
      "* I used biological examples like warmth regulation and milk production to highlight the mammalian characteristics of chickens.\n",
      "* To address the common misconception that chickens are birds, I provided taxonomic context and explained why they're classified differently.\n",
      "* The final sentence \"By recognizing these traits, we can gain a deeper appreciation for the diversity of life on Earth\" was chosen because it ties together the various points made in the essay and encourages the reader to think more broadly about what it means to be a mammal.\n",
      "\n",
      "Word count: 276\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prepare the messages in the required format\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=statement),\n",
    "]\n",
    "\n",
    "# Invoke the LLM\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "Given a riddle, solve it the best you can.\n",
    "Provide a clear justification of your answer and the reasoning behind it.\n",
    "\n",
    "Statement:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Riddle = \"\"\"\n",
    "What has a face and two hands, but no arms or legs?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to this classic riddle is: A CLOCK.\n",
      "\n",
      "Here's my justification for this answer:\n",
      "\n",
      "1. **\"A face\"**: A clock has a face, which refers to the clock's dial or display that shows the time.\n",
      "2. **\"Two hands\"**: A clock typically has two hands: the short hour hand and the long minute hand. These hands are used to indicate the time on the clock face.\n",
      "\n",
      "However, despite having these features, a clock does not have arms or legs. The term \"arms\" in this context is likely being used metaphorically, referring to the hands that move around the clock face. Clocks do not have physical arms or legs like humans do.\n",
      "\n",
      "This answer fits all the criteria mentioned in the riddle, making it a clever and logical solution!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prepare the messages in the required format\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=Riddle),\n",
    "]\n",
    "\n",
    "# Invoke the LLM\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Order Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a sentiment analyzer. You classify conversations into three categories: positive, negative or neutral.\n",
    "Return only the sentiment, in lower cap and without punctuation.\n",
    "\n",
    "Conversation:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "conversation = \"\"\"\n",
    "Customer: Hi, I need some help with my order.\n",
    "AI agent: Hello, welcome to our online store. I'm an AI agent and I'm here to assist you. \n",
    "Customer: I ordered a pair of shoes yesterday, but I haven't received a confirmation email yet. Can you check the status of my order?\n",
    "AI agent: Sure, I can help you with that. Can you please provide me with your order number and email address?\n",
    "Customer: Yes, my order number is 123456789 and my email is john.doe@example.com.\n",
    "AI agent: Thank you. I have found your order in our system. It looks like your order is still being processed and it will be shipped soon. You should receive a confirmation email within 24 hours.\n",
    "Customer: OK, thank you for the information. How long will it take for the shoes to arrive?\n",
    "AI agent: You're welcome. According to our shipping policy, it will take about 3 to 5 business days for the shoes to arrive at your address. You can track your order online using the tracking number that will be sent to your email once your order is shipped.\n",
    "Customer: Alright, sounds good. Thank you for your help.\n",
    "AI agent: It's my pleasure. Is there anything else I can do for you today?\n",
    "Customer: No, that's all. Have a nice day.\n",
    "AI agent: Thank you for choosing our online store. Have a nice day too. Goodbye. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prepare the messages in the required format\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=conversation),\n",
    "]\n",
    "\n",
    "# Invoke the LLM\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "You are a sentiment analyzer. You classify conversations into three categories: positive, negative or neutral.\n",
    "Return only the sentiment, in lower cap and without punctuation.\n",
    "\n",
    "Conversation:\n",
    "{conversation}\n",
    "\n",
    "Remember to return only the sentiment, in lower cap and without punctuation!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "neutral\n",
      "negative\n",
      "positive\n",
      "neutral\n",
      "positive\n",
      "neutral\n",
      "positive\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prepare the messages in the required format\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=conversation),\n",
    "]\n",
    "\n",
    "# Invoke the LLM\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "A neutron is a subatomic particle that has a neutral (not positive or negative) charge, and a mass slightly greater than that of a proton. \n",
    "It is present in all atomic nuclei except those of ordinary hydrogen. \n",
    "Neutrons, along with protons and electrons, are one of the three basic particles making up atoms. \n",
    "The term “neutron” comes from the fact that it is electrically neutral, meaning it carries no charge.\n",
    "\"\"\"\n",
    "\n",
    "system_message = f\"\"\"\n",
    "Reframe the text for a 5 years old child. It should be shorter than 500 words. Make a parallelism with animals.\n",
    "\n",
    "The text is the following:\n",
    "\n",
    "{text}\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a version of the text for a 5-year-old child:\n",
      "\n",
      "Do you know what makes up everything around us? It's tiny things called atoms! And inside those atoms, there are even smaller things called particles.\n",
      "\n",
      "One kind of particle is called a neutron. It's like a little ball that has no charge, which means it doesn't feel happy or sad because it can't send out any feelings. Imagine you're a rabbit and you have no feelings to share with your friends - that's what a neutron feels like!\n",
      "\n",
      "Neutrons are found in all kinds of atoms, except for one special kind called hydrogen. It's like how some animals live alone in the forest, while others live in big groups.\n",
      "\n",
      "Just like how we need different parts to make our bodies work, atoms need neutrons and other particles to be strong and healthy. And that's why scientists call them \"basic\" because they're so important!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prepare the messages in the required format\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=text),\n",
    "]\n",
    "\n",
    "# Invoke the LLM\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Use delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a Python expert that produces python code as per user's request.\n",
    "\n",
    "===>START EXAMPLE\n",
    "\n",
    "---User Query---\n",
    "Give me a function to print a string of text.\n",
    "\n",
    "---User Output---\n",
    "Below you can find the described function:\n",
    "```def my_print(text):\n",
    "     return print(text)\n",
    "```\n",
    "<===END EXAMPLE\n",
    "\"\"\"\n",
    "\n",
    "query = \"generate a python function to calculate the nth Fibonacci number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Fibonacci Number Calculator**\n",
      "=====================================\n",
      "\n",
      "The Fibonacci sequence is a series of numbers where a number is found by adding up the two numbers before it. Starting with 0 and 1, the sequence goes: 0, 1, 1, 2, 3, 5, 8, 13, ...\n",
      "\n",
      "Here's a Python function to calculate the nth Fibonacci number:\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    \"\"\"\n",
      "    Calculate the nth Fibonacci number.\n",
      "\n",
      "    Args:\n",
      "        n (int): The position of the Fibonacci number to calculate.\n",
      "\n",
      "    Returns:\n",
      "        int: The nth Fibonacci number.\n",
      "    \"\"\"\n",
      "\n",
      "    # Base cases\n",
      "    if n <= 0:\n",
      "        return \"Input should be a positive integer.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "\n",
      "    # Initialize variables for the recursive formula\n",
      "    a, b = 0, 1\n",
      "\n",
      "    # Calculate the nth Fibonacci number using recursion\n",
      "    for _ in range(2, n):\n",
      "        a, b = b, a + b\n",
      "\n",
      "    return b\n",
      "```\n",
      "\n",
      "**Example Usage:**\n",
      "```python\n",
      "print(fibonacci(10))  # Output: 55\n",
      "```\n",
      "\n",
      "This function uses an iterative approach to calculate the nth Fibonacci number. It starts with the base cases of `n <= 0`, `n == 1`, and `n == 2`, and then iteratively applies the recursive formula to calculate the nth Fibonacci number.\n",
      "\n",
      "**Note:** For large values of `n`, this function may be slow due to its recursive nature. In such cases, an iterative approach or memoization can improve performance.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prepare the messages in the required format\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=query),\n",
    "]\n",
    "\n",
    "# Invoke the LLM\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Few shot learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI marketing assistant. You help users to create taglines for new product names.\n",
    "Given a product name, produce a tagline similar to the following examples:\n",
    "\n",
    "Peak Pursuit - Conquer Heights with Comfort\n",
    "Summit Steps - Your Partner for Every Ascent\n",
    "Crag Conquerors - Step Up, Stand Tal\n",
    "\n",
    "Product name:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "product_name = 'Elevation Embrace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Fibonacci Number Calculator**\n",
      "=====================================\n",
      "\n",
      "Here is a Python function that calculates the nth Fibonacci number using an iterative approach:\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    \"\"\"\n",
      "    Calculate the nth Fibonacci number.\n",
      "\n",
      "    Args:\n",
      "        n (int): The position of the Fibonacci number to calculate.\n",
      "\n",
      "    Returns:\n",
      "        int: The nth Fibonacci number.\n",
      "    \"\"\"\n",
      "    if n <= 0:\n",
      "        return \"Input should be a positive integer.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "\n",
      "    fib_prev = 0\n",
      "    fib_curr = 1\n",
      "\n",
      "    for _ in range(3, n + 1):\n",
      "        fib_next = fib_prev + fib_curr\n",
      "        fib_prev = fib_curr\n",
      "        fib_curr = fib_next\n",
      "\n",
      "    return fib_curr\n",
      "```\n",
      "**Example Use Cases**\n",
      "--------------------\n",
      "\n",
      "```python\n",
      "print(fibonacci(10))  # Output: 55\n",
      "print(fibonacci(20))  # Output: 6765\n",
      "```\n",
      "This function uses a simple iterative approach to calculate the nth Fibonacci number. It starts with the base cases `n = 1` and `n = 2`, where the first two Fibonacci numbers are 0 and 1, respectively. Then, it iterates from `n = 3` to `n`, calculating each subsequent Fibonacci number as the sum of the previous two.\n",
      "\n",
      "**Note**: This function has a time complexity of O(n), making it efficient for large values of n. However, for very large values of n, you may want to consider using a more advanced algorithm or data structure, such as matrix exponentiation or memoization.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prepare the messages in the required format\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=query),\n",
    "]\n",
    "\n",
    "# Invoke the LLM\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "To solve a generic first-degree equation, follow these steps:\n",
    "\n",
    "1. **Identify the Equation:** Start by identifying the equation you want to solve. It should be in the form of \"ax + b = c,\" where 'a' is the coefficient of the variable, 'x' is the variable, 'b' is a constant, and 'c' is another constant.\n",
    "\n",
    "2. **Isolate the Variable:** Your goal is to isolate the variable 'x' on one side of the equation. To do this, perform the following steps:\n",
    "   \n",
    "   a. **Add or Subtract Constants:** Add or subtract 'b' from both sides of the equation to move constants to one side.\n",
    "   \n",
    "   b. **Divide by the Coefficient:** Divide both sides by 'a' to isolate 'x'. If 'a' is zero, the equation may not have a unique solution.\n",
    "\n",
    "3. **Simplify:** Simplify both sides of the equation as much as possible.\n",
    "\n",
    "4. **Solve for 'x':** Once 'x' is isolated on one side, you have the solution. It will be in the form of 'x = value.'\n",
    "\n",
    "5. **Check Your Solution:** Plug the found value of 'x' back into the original equation to ensure it satisfies the equation. If it does, you've found the correct solution.\n",
    "\n",
    "6. **Express the Solution:** Write down the solution in a clear and concise form.\n",
    "\n",
    "7. **Consider Special Cases:** Be aware of special cases where there may be no solution or infinitely many solutions, especially if 'a' equals zero.\n",
    "\n",
    "\n",
    "Equation:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "equation = \"3x + 5 = 11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve for x, we'll follow the steps:\n",
      "\n",
      "1. Identify the equation: 3x + 5 = 11\n",
      "2. Isolate the variable:\n",
      "   a. Subtract 5 from both sides of the equation to move constants to one side.\n",
      "      3x + 5 - 5 = 11 - 5\n",
      "      3x = 6\n",
      "\n",
      "   b. Divide both sides by 3 to isolate x.\n",
      "      (3x) / 3 = 6 / 3\n",
      "      x = 2\n",
      "3. Simplify: No simplification needed in this case.\n",
      "\n",
      "4. Solve for 'x': x = 2\n",
      "\n",
      "5. Check Your Solution: Plug the found value of x back into the original equation to ensure it satisfies the equation.\n",
      "   3(2) + 5 = 11\n",
      "   6 + 5 = 11\n",
      "   11 = 11 (True)\n",
      "\n",
      "The solution is correct.\n",
      "\n",
      "Final Answer: The final answer is 2.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prepare the messages in the required format\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=equation),\n",
    "]\n",
    "\n",
    "# Invoke the LLM\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
